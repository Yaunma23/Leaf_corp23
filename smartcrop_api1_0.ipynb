{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oVmNbNKaAqnD",
        "outputId": "e9b147b1-8d4b-4394-fcd2-313cde08b234"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "ðŸ”¹ Predictions from Test Dataset:\n",
            "   temperature humidity soil moisture      pH\n",
            "0         High      Low          High  Normal\n",
            "1         High      Low          High  Normal\n",
            "2         High      Low          High  Normal\n",
            "3         High      Low          High  Normal\n",
            "4         High      Low          High  Normal\n",
            "..         ...      ...           ...     ...\n",
            "68        High      Low          High  Normal\n",
            "69        High      Low          High  Normal\n",
            "70        High      Low          High  Normal\n",
            "71        High      Low          High  Normal\n",
            "72        High      Low          High  Normal\n",
            "\n",
            "[73 rows x 4 columns]\n",
            "\n",
            "ðŸ”¹ Model Accuracy per Feature:\n",
            "temperature: 0.95\n",
            "humidity: 1.00\n",
            "soil moisture: 0.95\n",
            "pH: 0.95\n",
            "\n",
            "ðŸ”¹ Thresholds Used for Categorization:\n",
            "temperature: Low < 22.69, Normal (22.69 - 24.89), High > 24.89\n",
            "humidity: Low < 81.44, Normal (81.44 - 83.04), High > 83.04\n",
            "soil moisture: Low < 218.41, Normal (218.41 - 257.01), High > 257.01\n",
            "pH: Low < 6.01, Normal (6.01 - 6.94), High > 6.94\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gspread\n",
        "from google.oauth2.service_account import Credentials\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Google Sheets API Setup\n",
        "SERVICE_ACCOUNT_FILE = \"/content/leaf-corp-d0623cb78464.json\"  # Replace with your service account JSON file\n",
        "SCOPES = [\"https://www.googleapis.com/auth/spreadsheets\"]\n",
        "\n",
        "creds = Credentials.from_service_account_file(SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "client = gspread.authorize(creds)\n",
        "\n",
        "# Open the Google Sheet by ID\n",
        "SHEET_ID = \"14g98RZnbqtrIfxyihWw6AWhOGLwcqh_1MOz-aryR6lA\"  # Replace with actual Sheet ID\n",
        "SHEET_NAME = \"Chilli_data_train\"  # Change if necessary\n",
        "sheet = client.open_by_key(SHEET_ID).worksheet(SHEET_NAME)\n",
        "\n",
        "# Load data into DataFrame\n",
        "data = sheet.get_all_values()\n",
        "df = pd.DataFrame(data[1:], columns=data[0])  # First row as column names\n",
        "\n",
        "# Convert numeric columns\n",
        "df.iloc[:, 1:] = df.iloc[:, 1:].apply(pd.to_numeric, errors='coerce')\n",
        "\n",
        "# Function to categorize values into Low, Normal, and High\n",
        "def categorize_features(data):\n",
        "    categorized_data = data.copy()\n",
        "    thresholds = {}  # Store threshold values\n",
        "\n",
        "    for col in data.columns:\n",
        "        low_thresh = np.percentile(data[col], 33)  # 33rd percentile\n",
        "        high_thresh = np.percentile(data[col], 67)  # 67th percentile\n",
        "        thresholds[col] = (low_thresh, high_thresh)\n",
        "\n",
        "        categorized_data[col] = np.select(\n",
        "            [data[col] < low_thresh, data[col] >= high_thresh],\n",
        "            ['Low', 'High'],\n",
        "            default='Normal'\n",
        "        )\n",
        "\n",
        "    return categorized_data, thresholds\n",
        "\n",
        "# Extract only relevant feature columns\n",
        "def process_common_data(df):\n",
        "    feature_columns = ['temperature', 'humidity', 'soil moisture', 'pH']\n",
        "    df = df[feature_columns]  # Keep only necessary columns\n",
        "    df = df.apply(pd.to_numeric, errors='coerce')  # Convert to numeric\n",
        "    df = df.dropna()  # Drop missing values\n",
        "    return df\n",
        "\n",
        "# Process training data\n",
        "df = process_common_data(df)\n",
        "\n",
        "# Convert numerical values to categories\n",
        "categorized_df, thresholds = categorize_features(df)\n",
        "\n",
        "# Prepare Features (X) and Target (y)\n",
        "X = df  # Numerical dataset\n",
        "y = categorized_df  # Categorical dataset (Low/Normal/High)\n",
        "\n",
        "# Split data (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a Decision Tree Classifier for each feature\n",
        "models = {}\n",
        "for column in y.columns:\n",
        "    model = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
        "    model.fit(X_train, y_train[column])\n",
        "    models[column] = model\n",
        "\n",
        "# Function to predict categories on new test data\n",
        "def predict_categories(test_sheet_id, test_sheet_name):\n",
        "    test_sheet = client.open_by_key(test_sheet_id).worksheet(test_sheet_name)\n",
        "    test_data = test_sheet.get_all_values()\n",
        "    test_df = pd.DataFrame(test_data[1:], columns=test_data[0])\n",
        "\n",
        "    # Process only common columns\n",
        "    test_df = process_common_data(test_df)\n",
        "\n",
        "    # Make predictions for each feature\n",
        "    predictions = {}\n",
        "    for feature, model in models.items():\n",
        "        predictions[feature] = model.predict(test_df)\n",
        "\n",
        "    results = pd.DataFrame(predictions)\n",
        "    return results\n",
        "\n",
        "# Test the model with a new dataset from Google Sheets\n",
        "TEST_SHEET_ID = \"1XdXlgTWxEDfU0uHK1Z3mM885JQuM0EH16DrDaIHP3zc\"  # Replace with test Google Sheet ID\n",
        "TEST_SHEET_NAME = \"Sheet1\"\n",
        "\n",
        "predictions = predict_categories(TEST_SHEET_ID, TEST_SHEET_NAME)\n",
        "\n",
        "print(\"\\nðŸ”¹ Predictions from Test Dataset:\")\n",
        "print(predictions)\n",
        "\n",
        "# Evaluate model accuracy\n",
        "accuracy = {}\n",
        "for column in y.columns:\n",
        "    y_pred = models[column].predict(X_test)\n",
        "    accuracy[column] = accuracy_score(y_test[column], y_pred)\n",
        "\n",
        "print(\"\\nðŸ”¹ Model Accuracy per Feature:\")\n",
        "for feature, acc in accuracy.items():\n",
        "    print(f\"{feature}: {acc:.2f}\")\n",
        "\n",
        "# Show threshold values used\n",
        "print(\"\\nðŸ”¹ Thresholds Used for Categorization:\")\n",
        "for feature, (low, high) in thresholds.items():\n",
        "    print(f\"{feature}: Low < {low:.2f}, Normal ({low:.2f} - {high:.2f}), High > {high:.2f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
